기존 RDBMS가 익숙한 개발자라면 우선 다음과 같은 개념을 확립하고 가야한다.

| RDBMS  | 오픈서치 |
| ------ | -------- |
| Table  | Index    |
| Row    | Document |
| Column | Field    |

## 시작하기

이제 기본적인 쿼리를 알아보자.

**루트 레벨 키**

| key   | 설명                             |
| ----- | -------------------------------- |
| query | 쿼리문 작성                      |
| aggs  | 데이터 그룹화 통계 (Aggregation) |
| sort  | 정렬                             |
| size  | 결과 (LIMIT)                     |
![](https://i.imgur.com/LmF3xil.png)

한글도 다뤄야할 경우 아래 nori 플러그인을 설치해야한다.

`curl -X GET "localhost:9200/_cat/plugins?v"`를 입력해서 nori 플러그인이 설치되어있는지 확인 가능하다. 쿼리 결과로 nori라는 텍스트가 보이지 않는다면 아래 명령어를 실행해 nori를 설치한다.

`docker exec -it [컨테이너명] bin/opensearch-plugin install analysis-nori`

이제 특정 index에 nori를 사용하겠다는 설정을 해야하는데, 다음과 같다.

```json
PUT /recipe
{
  "settings": {
    "index": {
      "number_of_shards": 1,
      "number_of_replicas": 0,
    },
    "analysis": {
      "analyzer": {
        "my_nori_analyzer": {          // 1. 분석기 이름 (내 마음대로 정함)
          "type": "custom",
          "tokenizer": "my_nori_tokenizer", // 2. Nori 토크나이저 사용
          "filter": [
			  "lowercase", // 영어는 소문자로 변환해서 검색 품질 향상
			  "nori_part_of_speech", // 조사 버리는 옵션
			  "asciifolding", // 특수 알파벳 처리
			  "nori_readingform" // 한자 -> 한글 변환
		  ]        
        }
      },
      "tokenizer": {
        "my_nori_tokenizer": {
          "type": "nori_tokenizer",
          "decompound_mode": "mixed"
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "my_nori_analyzer"
      }
    }
  }
}
```

위 옵션들에 대해 간략하게 설명해보겠다.
`PUT /recipe`: /recipe 인덱스에 위 옵션을 설정한다.
`number_of_shards`: 샤드 갯수를 한 개로 지정한다. (분산 저장 안 함)
`number_of_replicas`: 복제본 갯수를 0개로 지정한다. (복제 저장 안 함)

여기서 shards와 replicas가 헷갈릴 수 있는데, shards는 한 덩어리를 나눠서 분산 저장하는 것이고 replicas는 한 덩어리와, 이를 나눠서 저장하는 샤드를 총괄적으로 아예 복사본을 가지는 것이다.

따라서 내가 replicas를 1로 설정하고, shards를 3으로 설정하게 된다면 인덱스를 3조각으로 나눈것의 복사본을 가지고 있는 것이기 때문에 총 shards는 6개가 되는 것이다.


### Analyzer 설정
analyzer 설정의 filter에 다양한 필터를 명시해놓은 것을 알 수 있는데 각 항목들의 기능에 대해 알아보자.

`lowercase`: 대소문자 구분 없이 검색 가능한 설정
`nori_part_of_speech`: 조사 은, 는, 이, 가 등이나 ~보다, ~랑 등 검색에 쓸 데 없는 조사나 형태소를 버린다.
`asciifolding`: 문서에 `café`라고 되어 있을 때 `cafe`로도 검색할 수 있게 한다. 반대 경우도 마찬가지.
`nori_readingform`: 문서에는 `高靈 (고령)`이라고 적혀 있을 때 `고령`으로 검색할 수 있게 한다.

### Tokenizer 설정
`decompound_mode`에는 세 가지 타입이 있다.

- none: "김치찌개"를 "김치찌개"로만 토큰화한다.
- discard: "김치찌개"를 "김치", "찌개"로 토큰화한다.
- mixed: "김치찌개"를 "김치찌개", "김치", "찌개"로 토큰화한다.

서치 파이프라인 설정
```json
PUT /_search/pipeline/hybrid-search-pipeline
{
  "description": "Nori + Dense + Sparse 점수를 합치기 위한 파이프라인",
  "phase_results_processors": [
    {
      "normalization-processor": {
        "normalization": {
          "technique": "min_max"   // 모든 점수를 0~1 사이로 변환
        },
        "combination": {
          "technique": "arithmetic_mean", // 정규화된 점수들을 산술 평균(합산)
          "parameters": {
            "weights": [0.3, 0.4, 0.3]    // [Nori, Dense, Sparse] 순서대로 비중 조절
          }
        }
      }
    }
  ]
}
```